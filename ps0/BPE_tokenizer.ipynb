{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb4f27cd",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "eb4f27cd"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aa7dd589",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa7dd589",
        "outputId": "b6a7c862-9408-4799-f9ee-eddca7267f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O shakespeare.txt\n",
        "\n",
        "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2196bd8c",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "2196bd8c"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "def corpus_to_tokens(text: str) -> List[str]:\n",
        "\n",
        "    return list(text)\n",
        "\n",
        "def get_pair_stats(tokens: List[str]) -> Dict[Tuple[str, str], int]:\n",
        "\n",
        "    stats = Counter()\n",
        "    if len(tokens) < 2:\n",
        "        return stats\n",
        "    prev = tokens[0]\n",
        "    for t in tokens[1:]:\n",
        "        stats[(prev, t)] += 1\n",
        "        prev = t\n",
        "    return stats\n",
        "\n",
        "def merge_tokens(tokens: List[str], pair: Tuple[str, str]) -> List[str]:\n",
        "\n",
        "    a, b = pair\n",
        "    new_token = a + b\n",
        "    new_tokens = []\n",
        "    i = 0\n",
        "    L = len(tokens)\n",
        "    while i < L:\n",
        "        if i < L - 1 and tokens[i] == a and tokens[i + 1] == b:\n",
        "            new_tokens.append(new_token)\n",
        "            i += 2\n",
        "        else:\n",
        "            new_tokens.append(tokens[i])\n",
        "            i += 1\n",
        "    return new_tokens\n",
        "\n",
        "def fit_bpe(\n",
        "    text: str,\n",
        "    num_merges: int = 300,\n",
        "    verbose: bool = True\n",
        "):\n",
        "\n",
        "    tokens = corpus_to_tokens(text)\n",
        "    vocab = set(tokens)\n",
        "    merges: List[Tuple[str, str]] = []\n",
        "\n",
        "    for i in range(num_merges):\n",
        "        stats = get_pair_stats(tokens)\n",
        "        if not stats:\n",
        "            if verbose:\n",
        "                print(f\"[Step {i}] no avialable pairs!\")\n",
        "            break\n",
        "\n",
        "        # max freq pair\n",
        "        best_pair, best_freq = max(stats.items(), key=lambda kv: kv[1])\n",
        "\n",
        "        tokens = merge_tokens(tokens, best_pair)\n",
        "        merges.append(best_pair)\n",
        "        vocab.add(best_pair[0] + best_pair[1])\n",
        "\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"vocab\": vocab,\n",
        "        \"merges\": merges    # merge rules\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "543280e0",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "543280e0",
        "outputId": "1e6acc73-e86c-4fd0-e8e6-7b320ef57824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done!\n",
            "total merge steps: 300\n",
            "final vocab size: 365\n"
          ]
        }
      ],
      "source": [
        "NUM_MERGES = 300\n",
        "\n",
        "bpe_model = fit_bpe(\n",
        "    text,\n",
        "    num_merges=NUM_MERGES,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "merges = bpe_model[\"merges\"]\n",
        "vocab  = bpe_model[\"vocab\"]\n",
        "\n",
        "print(\"Training done!\")\n",
        "print(\"total merge steps:\", len(merges))\n",
        "print(\"final vocab size:\", len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0e08fecb",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e08fecb",
        "outputId": "fb24afc3-c6f3-40f4-bc2d-7910026a9bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== first few merge rules ===\n",
            "   1: ('e', ' ') -> 'e '\n",
            "   2: ('t', 'h') -> 'th'\n",
            "   3: ('t', ' ') -> 't '\n",
            "   4: ('s', ' ') -> 's '\n",
            "   5: ('d', ' ') -> 'd '\n",
            "   6: (',', ' ') -> ', '\n",
            "   7: ('o', 'u') -> 'ou'\n",
            "   8: ('e', 'r') -> 'er'\n",
            "   9: ('i', 'n') -> 'in'\n",
            "  10: ('y', ' ') -> 'y '\n",
            "  11: ('a', 'n') -> 'an'\n",
            "  12: (':', '\\n') -> ':\\n'\n",
            "  13: ('o', 'r') -> 'or'\n",
            "  14: ('o', ' ') -> 'o '\n",
            "  15: ('e', 'n') -> 'en'\n",
            "  16: ('\\n', '\\n') -> '\\n\\n'\n",
            "  17: ('a', 'r') -> 'ar'\n",
            "  18: (' ', 'th') -> ' th'\n",
            "  19: ('o', 'n') -> 'on'\n",
            "  20: ('l', 'l') -> 'll'\n",
            "...\n",
            "\n",
            "=== lasr few merge rules ===\n",
            " 291: (' a', 'm') -> ' am'\n",
            " 292: (' th', 'y ') -> ' thy '\n",
            " 293: ('O', 'N') -> 'ON'\n",
            " 294: (' h', 'e ') -> ' he '\n",
            " 295: ('in', ' ') -> 'in '\n",
            " 296: ('r', 'an') -> 'ran'\n",
            " 297: ('in', 'k') -> 'ink'\n",
            " 298: ('s', 'a') -> 'sa'\n",
            " 299: ('d', 'ea') -> 'dea'\n",
            " 300: ('an', ' ') -> 'an '\n"
          ]
        }
      ],
      "source": [
        "def show_merges(merges, n_head=30, n_tail=10):\n",
        "    print(\"=== first few merge rules ===\")\n",
        "    for i, (a, b) in enumerate(merges[:n_head]):\n",
        "        print(f\"{i+1:4d}: ({repr(a)}, {repr(b)}) -> {repr(a+b)}\")\n",
        "\n",
        "    if len(merges) > n_head + n_tail:\n",
        "        print(\"...\")\n",
        "    if n_tail > 0:\n",
        "        print(\"\\n=== lasr few merge rules ===\")\n",
        "        for i, (a, b) in enumerate(merges[-n_tail:], start=len(merges)-n_tail+1):\n",
        "            print(f\"{i:4d}: ({repr(a)}, {repr(b)}) -> {repr(a+b)}\")\n",
        "\n",
        "show_merges(merges, n_head=20, n_tail=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "75aae69d",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75aae69d",
        "outputId": "f06fe1f2-143a-428d-9de6-7e6cafd33ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial string:\n",
            "Alas, poor Yorick! I knew him, Horatio:\n",
            "\n",
            "BPE encoded token seq:\n",
            "['A', 'la', 's, ', 'po', 'or', ' ', 'Y', 'or', 'i', 'ck', '! ', 'I ', 'k', 'ne', 'w', ' him', ', ', 'H', 'or', 'at', 'i', 'o', ':']\n",
            "\n",
            "Numer of tokens: 23\n"
          ]
        }
      ],
      "source": [
        "def bpe_encode(text: str, merges: List[Tuple[str, str]]) -> List[str]:\n",
        "\n",
        "    tokens = list(text)\n",
        "    for pair in merges:\n",
        "        tokens = merge_tokens(tokens, pair)\n",
        "    return tokens\n",
        "\n",
        "test_str = \"Alas, poor Yorick! I knew him, Horatio:\"\n",
        "encoded = bpe_encode(test_str, merges)\n",
        "\n",
        "print(\"initial string:\")\n",
        "print(test_str)\n",
        "print(\"\\nBPE encoded token seq:\")\n",
        "print(encoded)\n",
        "print(\"\\nNumer of tokens:\", len(encoded))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}